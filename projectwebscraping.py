# -*- coding: utf-8 -*-
"""ProjectWebscraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/Ayanlola2002/Technidus_project/blob/master/ProjectWebscraping.ipynb

### Web Scraping

####  Propertypro is more flexible in terms of legal right as seen in the terms and conditions page.   

#### https://www.propertypro.ng/terms
#### https://nigeriapropertycentre.com/terms-of-use

.

#### Import Beautiful Soup for scraping, 
####requests for making request to a website and 
#### re for regular expressions
"""

import requests, re
from bs4 import BeautifulSoup

"""#### Making a request to the website and extract its content (page source)"""

r=requests.get("https://www.propertypro.ng/property-for-rent?search=gbagada")
c=r.content

"""#### Parsing page source using the Beautiful soup HTML parser
#### Find all property features on the page.
#### I did this by first expecting the web page
"""

#beautifulsoup object
soup=BeautifulSoup(c,"html.parser")

real=soup.find_all("div",{"class":"prop-features"})

#checking features to remove
real[0].get_text().strip().split()

re.findall("..bath",real[0].get_text().strip())#[0][0]

"""#### changing div and class below to search for something else. """

real=soup.find_all("div",{"class":"prop-features"})

#https://www.propertypro.ng/property-for-rent?search=gbagada&page=1

#trying to establish page number
items = int(re.findall("\d+",soup.find_all("div",{"class":"jumbotron m-hide"})[0].text.split("total of")[1][:6].replace(",","").strip())[0])
listings = 20
page_nr = int(items/listings)
page_nr

#WebScrape Code
l=[]
location = ["gbagada","ikeja","surulere","ikeja","ogba","iyana ipaja","lekki","ajah","ikorodu"]


for place in location:
    base_url="https://www.propertypro.ng/property-for-rent?search="+place+ "&auto=&type=&bedroom=&max_price="
    r=requests.get(base_url+".html")
    c=r.content
    soup=BeautifulSoup(c,"html.parser")

    items = int(re.findall("\d+",soup.find_all("div",{"class":"jumbotron m-hide"})[0].text.split("total of")[1][:6].replace(",","").strip())[0])
    listings = 20 #This can be edited back to 20 items as stated on site. However your code will take a while to run
    page_nr = int(items/listings)
    
    #base_url="https://www.propertypro.ng/property-for-rent?search="+place+ "&auto=&type=&bedroom=&max_price="
    for page in range(1,int(page_nr),1):

        r=requests.get(base_url+".html"+"&page="+str(page))
        c=r.content

        soup=BeautifulSoup(c,"html.parser")
        
        classes = ["col-lg-6 col-md-6 col-sm-6 col-xs-12 prop-meta-data","col-lg-8 col-md-8 col-sm-7 col-xs-12 prop-meta-data text-left",
                   "col-lg-9 col-md-9 col-sm-12 col-xs-12 main-listing-cont"]
        for class_ in classes:
            real=soup.find_all("div",{"class":class_})

            for i in list(range(0,len(real))):
                d={}
                d['page']= page
                try:
                    d["location"] = real[i].find("h3",{"class":"pro-location"}).text.strip()
                except (IndexError,TypeError,AttributeError):
                    d["location"] = None
                try:
                    d["specific_location"] = real[i].find("h3",{"class":"pro-location"}).text.strip().split("gbagada")[0].replace("-","").strip()
                except(IndexError,TypeError,AttributeError):
                    d['specific_location'] = None
                try:
                    d["features"]=real[i].find("span",{"class":"prop-aminities float-left"}).text.strip()  
                except (AttributeError,IndexError) as e:
                    d["features"]= None
                try:
                    d["bedrooms"]= re.findall("..bed",real[i].find("span",{"class":"prop-aminities float-left"}).text.strip())[0][0]
                except (IndexError,TypeError,AttributeError) as e:
                    d["bedrooms"]= None 
                try:
                    d["bathrooms"]= re.findall("..bath",real[i].find("span",{"class":"prop-aminities float-left"}).text.strip())[0][0]
                except (IndexError,TypeError,AttributeError) as e:
                    d["bathrooms"]= None
                try:
                    d["toilets"]= re.findall("..toilet",real[i].find("span",{"class":"prop-aminities float-left"}).text.strip())[0][0]
                except (IndexError,TypeError,AttributeError) as e:
                    d["toilets"]=None
                try:
                    d["description"]=real[i].find("p",{"class":"pro-description"}).text.strip()
                except (IndexError,TypeError,AttributeError) as e:
                    d["description"]= None
                try:
                    d["other_description"]=real[i].find("p",{"class":"pro-description readmore"}).text.strip()
                except (IndexError,TypeError,AttributeError) as e:
                    d["other_description"]= None     
                
                try:
                    d["price"]=real[i].find("p",{"class":"prop-price"}).text.strip().replace("â‚¦","").replace(",","")
                except (IndexError,TypeError,AttributeError) as e:
                    d["price"] = None
                l.append(d)
                #print(l)
                #print(" "

"""#### Convert output to dataframe"""

import pandas as pd
ld = pd.DataFrame(l)
ld

scrapedata=ld.to_csv("data1.csv",index=False)

#data check
ld.head(10)

#check rows with null values
sum(ld.apply(lambda x: sum(x.isnull().values), axis = 0)>0)

#removing all null values
ld = ld.dropna(how='any',axis=0)

#checking for null values
ld.isnull().sum()

#ld['location'] = ld['location'].str.extract(r'(gbagada|ikeja|surulere|ogba|iyana ipaja|lekki|ajah|ikorodu)').map({'gbagada':'gbagada','ikeja':'ikeja','ogba':'ogba','iyana ipaja':'iyana ipaja','lekki':'lekki','ajah':'ajah','ikorodu':'ikorodu'})

#changing location content
ld["location"][ld['location'].str.contains("gbagada")] ="gbagada"
ld["location"][ld['location'].str.contains("ikeja")] ="ikeja"
ld["location"][ld['location'].str.contains("iyana ipaja")] ="iyana ipaja"
ld["location"][ld['location'].str.contains("surulere")] ="surulere"
ld["location"][ld['location'].str.contains("ogba")] ="ogba"
ld["location"][ld['location'].str.contains("lekki")] ="lekki"
ld["location"][ld['location'].str.contains("ajah")] ="ajah"
ld["location"][ld['location'].str.contains("ikorodu")] ="ikorodu"

#testing the values
ld['location'][ld['location']=='ogba']

ld.head()